{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model Optimization: Exploratory Analysis\n",
    "## Human-Guided Interaction Term Engineering\n",
    "\n",
    "**Expert**: Enzo Rodriguez  \n",
    "**Task ID**: TASK_11251  \n",
    "**Model**: Buffalo (Claude Sonnet 4.5)  \n",
    "**Date**: 2026-02-10\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates the complete workflow for optimizing ML models through correlation analysis and interaction term engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from data_processing import DataProcessor\n",
    "from correlation_analysis import CorrelationAnalyzer\n",
    "from interaction_engineering import InteractionEngineer\n",
    "from model_training import ModelTrainer\n",
    "from evaluation import ModelEvaluator, compare_multiple_models\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data processor\n",
    "processor = DataProcessor()\n",
    "\n",
    "# Load data - UPDATE THIS PATH\n",
    "data_path = '../data/raw/your_dataset.csv'\n",
    "target_col = 'target'  # UPDATE THIS\n",
    "\n",
    "data = processor.load_data(data_path)\n",
    "\n",
    "# Display first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and print data profile\n",
    "processor.print_data_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = data.isnull().sum()\n",
    "missing[missing > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "if data.isnull().sum().sum() > 0:\n",
    "    data = processor.handle_missing_values(strategy='median')\n",
    "\n",
    "# Handle outliers\n",
    "data = processor.handle_outliers(method='iqr', threshold=1.5)\n",
    "\n",
    "print(f\"\\nCleaned data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables if present\n",
    "categorical_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "if target_col in categorical_cols:\n",
    "    categorical_cols.remove(target_col)\n",
    "\n",
    "if categorical_cols:\n",
    "    data = processor.encode_categorical_variables(columns=categorical_cols, method='onehot')\n",
    "    print(f\"Encoded {len(categorical_cols)} categorical columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize correlation analyzer\n",
    "analyzer = CorrelationAnalyzer(data=data, target_col=target_col)\n",
    "\n",
    "# Compute correlations\n",
    "corr_matrix = analyzer.compute_correlation_matrix(method='pearson')\n",
    "target_corr = analyzer.compute_target_correlations(method='pearson')\n",
    "\n",
    "# Display top correlations with target\n",
    "target_corr.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation heatmap\n",
    "analyzer.plot_correlation_heatmap(figsize=(14, 12), save_path='../results/correlation_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target correlations\n",
    "analyzer.plot_target_correlations(top_n=20, save_path='../results/target_correlations.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify multicollinearity\n",
    "multicoll = analyzer.identify_multicollinearity(threshold=0.8)\n",
    "print(f\"Found {len(multicoll)} highly correlated feature pairs\\n\")\n",
    "multicoll.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify interaction candidates\n",
    "interaction_candidates = analyzer.identify_interaction_candidates(\n",
    "    target_corr_threshold=0.1,\n",
    "    feature_corr_range=(0.1, 0.7),\n",
    "    top_n=20\n",
    ")\n",
    "\n",
    "interaction_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comprehensive correlation report\n",
    "analyzer.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interaction Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize interaction engineer\n",
    "engineer = InteractionEngineer(data=data, target_col=target_col)\n",
    "\n",
    "# Create interaction pairs from top candidates\n",
    "top_n = 10\n",
    "interaction_pairs = [\n",
    "    (row['feature_1'], row['feature_2'])\n",
    "    for _, row in interaction_candidates.head(top_n).iterrows()\n",
    "]\n",
    "\n",
    "print(f\"Creating {len(interaction_pairs)} interaction terms...\")\n",
    "for pair in interaction_pairs:\n",
    "    print(f\"  • {pair[0]} × {pair[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiplicative interactions\n",
    "interactions = engineer.batch_create_interactions(\n",
    "    interaction_pairs,\n",
    "    interaction_type='multiplicative'\n",
    ")\n",
    "\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate interaction importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "importance = engineer.evaluate_interaction_importance(\n",
    "    interactions,\n",
    "    estimator=model,\n",
    "    cv=5,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize interaction importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_interactions = importance.head(15)\n",
    "plt.barh(top_interactions['interaction_term'], top_interactions['improvement'], alpha=0.7)\n",
    "plt.xlabel('R² Improvement', fontsize=12)\n",
    "plt.ylabel('Interaction Term', fontsize=12)\n",
    "plt.title('Top Interaction Terms by Model Improvement', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='red', linestyle='--', linewidth=1)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/interaction_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best interactions\n",
    "best_interactions = engineer.select_best_interactions(\n",
    "    importance,\n",
    "    threshold=0.0,\n",
    "    top_n=None\n",
    ")\n",
    "\n",
    "print(f\"\\nSelected {len(best_interactions)} beneficial interactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced dataset\n",
    "enhanced_data = engineer.add_interactions_to_data(interactions[best_interactions])\n",
    "\n",
    "print(f\"Original features: {data.shape[1] - 1}\")\n",
    "print(f\"Enhanced features: {enhanced_data.shape[1] - 1}\")\n",
    "print(f\"Added interactions: {len(best_interactions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model trainer\n",
    "trainer = ModelTrainer(\n",
    "    data=data,\n",
    "    target_col=target_col,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    scale_features=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline models\n",
    "baseline_results = trainer.train_baseline_models(cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train enhanced model with interactions\n",
    "enhanced_results = trainer.train_enhanced_model(\n",
    "    enhanced_data=enhanced_data,\n",
    "    model_name='Enhanced Random Forest',\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "trainer.print_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluators for all models\n",
    "evaluators = []\n",
    "\n",
    "# Baseline models\n",
    "for name, results in baseline_results.items():\n",
    "    evaluator = ModelEvaluator(\n",
    "        y_true=trainer.y_test,\n",
    "        y_pred=results['predictions_test'],\n",
    "        model_name=f\"Baseline - {name}\"\n",
    "    )\n",
    "    evaluators.append(evaluator)\n",
    "\n",
    "# Enhanced model\n",
    "for name, results in trainer.enhanced_results.items():\n",
    "    evaluator = ModelEvaluator(\n",
    "        y_true=results['y_test'],\n",
    "        y_pred=results['predictions_test'],\n",
    "        model_name=name\n",
    "    )\n",
    "    evaluators.append(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print evaluation reports\n",
    "for evaluator in evaluators:\n",
    "    evaluator.print_evaluation_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "comparison = compare_multiple_models(evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize best enhanced model\n",
    "best_enhanced = evaluators[-1]  # Last one is typically the enhanced model\n",
    "\n",
    "best_enhanced.plot_predictions(save_path='../results/best_model_predictions.png')\n",
    "best_enhanced.plot_residuals(save_path='../results/best_model_residuals.png')\n",
    "best_enhanced.plot_error_distribution(save_path='../results/best_model_errors.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from enhanced model\n",
    "feature_importance = trainer.get_feature_importance('Enhanced Random Forest')\n",
    "\n",
    "feature_importance.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance.head(20)\n",
    "plt.barh(top_features['feature'], top_features['importance'], alpha=0.7)\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 20 Feature Importances (Enhanced Model)', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify interaction terms in top features\n",
    "interaction_features = feature_importance[feature_importance['feature'].str.contains('×')]\n",
    "print(f\"\\nInteraction terms in top 20 features: {len(interaction_features.head(20))}\")\n",
    "print(\"\\nTop interaction terms:\")\n",
    "interaction_features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "enhanced_data.to_csv('../data/processed/enhanced_data.csv', index=False)\n",
    "print(\"✓ Enhanced data saved\")\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance.to_csv('../results/feature_importance.csv', index=False)\n",
    "print(\"✓ Feature importance saved\")\n",
    "\n",
    "# Save model comparison\n",
    "comparison.to_csv('../results/model_comparison.csv', index=False)\n",
    "print(\"✓ Model comparison saved\")\n",
    "\n",
    "# Save best model\n",
    "trainer.save_model('Enhanced Random Forest', '../models/best_model.joblib')\n",
    "print(\"✓ Best model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete ML optimization workflow:\n",
    "\n",
    "1. **Data Loading & Preprocessing**: Handled missing values, outliers, and categorical encoding\n",
    "2. **Correlation Analysis**: Identified relationships between features and potential interaction candidates\n",
    "3. **Interaction Engineering**: Created and evaluated interaction terms\n",
    "4. **Model Training**: Trained baseline and enhanced models\n",
    "5. **Model Evaluation**: Comprehensive evaluation with statistical rigor\n",
    "6. **Feature Importance**: Analyzed which features (including interactions) contribute most\n",
    "\n",
    "### Key Insights\n",
    "- Review the model comparison table to see performance improvements\n",
    "- Check which interaction terms provide the most value\n",
    "- Examine residual plots to verify model assumptions\n",
    "- Consider domain knowledge when interpreting interaction terms\n",
    "\n",
    "### Next Steps\n",
    "- Experiment with different interaction types (ratio, difference, polynomial)\n",
    "- Try other correlation methods (Spearman, Kendall)\n",
    "- Tune hyperparameters for the best performing model\n",
    "- Validate on additional holdout data\n",
    "\n",
    "---\n",
    "\n",
    "**The Human Element**: This framework emphasizes human-guided optimization, where statistical analysis informs feature engineering decisions, leading to more interpretable and robust models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
